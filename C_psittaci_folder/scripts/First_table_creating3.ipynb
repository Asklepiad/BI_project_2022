{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rK9byz6M-4gr"
   },
   "source": [
    "### Uploading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from Bio.Seq import Seq\n",
    "from itertools import chain\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import Entrez\n",
    "Entrez.email = \"bogdan.sotnikov.1999@mail.ru\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qTr549eT0tml"
   },
   "outputs": [],
   "source": [
    "# Function for parsing assembly number\n",
    "def get_assembly_number(pre_pattern1, string):\n",
    "    pre_pattern2 = r\"_[\\d]+?\\.gbk\"\n",
    "    first_bound = re.search(pre_pattern1, string)\n",
    "    second_bound = re.search(pre_pattern2, string)\n",
    "    result = string[first_bound.end():(second_bound.start())]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "yjqDsdd99_20"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 23.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# Uploading the data \n",
    "#current_path = \"../data/C_psittaci_annotate/\" # Path directory\n",
    "current_path = \"../../../C_psittaci/new_ass/C_psittaci/\"\n",
    "pre_pattern1 = r\"C_psittaci\" # This pre_pattern1 may be used onle for C_psittaci assembly\n",
    "gb_records= []  # Reasserting the gb_records list\n",
    "gbk_files = os.listdir(current_path)\n",
    "\n",
    "for gbk in tqdm(gbk_files):\n",
    "    assembly_number = get_assembly_number(pre_pattern1, gbk)\n",
    "    link = f\"{current_path}{gbk}\"\n",
    "    gbk_object = SeqIO.read(link, 'genbank')\n",
    "    gb_records.append((gbk_object, assembly_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ya-4wM01v5OE"
   },
   "source": [
    "### Creating first table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading info about which DNA is plasmid\n",
    "with open(\"../data/C_psittaci_plasmid_code.json\", \"r\") as dictionary:\n",
    "    plasmid_code = json.load(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "248o-4h8wHDZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:09<00:00,  5.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# Parsing\n",
    "locus_tag, start_codone, source, n_sequence, aa_sequence, DNA_source, gene_pseudogene, product, cog, p_c_unity, additional_info = [], [], [], [], [], [], [], [], [], [], []\n",
    "for record_number in tqdm(range(len(gb_records))):\n",
    "    for feature_number in range(1, len(gb_records[record_number][0].features)):\n",
    "        if gb_records[record_number][0].features[feature_number].type == \"CDS\":\n",
    "            \n",
    "            ## Column 1 -- uniq id\n",
    "            if 'locus_tag' in gb_records[record_number][0].features[feature_number].qualifiers.keys():\n",
    "                locus_tag.append(gb_records[record_number][0].features[feature_number].qualifiers['locus_tag'][0])\n",
    "            else:\n",
    "                locus_tag.append(\"absent\")\n",
    "                \n",
    "            ## Column 2 -- source\n",
    "            source.append(gb_records[record_number][0].name)\n",
    "            \n",
    "            ## Column 3 -- nucleotide sequence & 7 -- start-codone\n",
    "            first = gb_records[record_number][0].features[feature_number].location.start\n",
    "            last = gb_records[record_number][0].features[feature_number].location.end\n",
    "            strand = gb_records[record_number][0].features[feature_number].location.strand\n",
    "            if strand == 1:\n",
    "                sequence = str(gb_records[record_number][0].seq[first:last])\n",
    "                n_sequence.append(sequence)\n",
    "                start_codone.append(sequence[0:3])\n",
    "            elif strand == -1:\n",
    "                sequence = str(gb_records[record_number][0].seq.complement()[first:last])[::-1]\n",
    "                n_sequence.append(sequence)\n",
    "                start_codone.append(sequence[0:3])\n",
    "            else:\n",
    "                n_sequence.append(\"absent\")\n",
    "                \n",
    "            ## Column 4 -- aminoacid sequence\n",
    "            if 'translation' in gb_records[record_number][0].features[feature_number].qualifiers.keys():\n",
    "                aa_sequence.append(gb_records[record_number][0].features[feature_number].qualifiers['translation'][0])\n",
    "            else:\n",
    "                aa_sequence.append(\"absent\")\n",
    "                \n",
    "#             ## Column 5 -- plasmid or chromosome\n",
    "#             if plasmid_code[str(gb_records[record_number][1])] == \"plasmid\":\n",
    "#                 DNA_source.append(\"plasmid\")\n",
    "#             else:\n",
    "#                 DNA_source.append(\"chromosome\")\n",
    "\n",
    "#             ## Column 6 -- gene or pseudogene\n",
    "            \n",
    "            # Column 7 -- protein, coding by this gene\n",
    "            if 'product' in gb_records[record_number][0].features[feature_number].qualifiers.keys():\n",
    "                product.append(gb_records[record_number][0].features[feature_number].qualifiers['product'][0])\n",
    "            else:\n",
    "                product.append(\"NA\")\n",
    "                \n",
    "            ## Column 8 -- COG number\n",
    "            if 'db_xref' in gb_records[record_number][0].features[feature_number].qualifiers.keys():\n",
    "                cog.append(gb_records[record_number][0].features[feature_number].qualifiers[\"db_xref\"][0][4:])\n",
    "            else:\n",
    "                cog.append(\"absent\")\n",
    "            \n",
    "            ## Column 9 -- number of molecule (for identification and further plasmid marking)\n",
    "            p_c_unity.append(gb_records[record_number][1])\n",
    "            \n",
    "            # Column 10 -- Record and feature number\n",
    "            additional_info.append((record_number, feature_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2e8OTrYR8_ho"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13731/4036676184.py:7: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \"type_of_DNA_source\": pd.Series(DNA_source),\n",
      "/tmp/ipykernel_13731/4036676184.py:8: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \"type_of_the_gene\": pd.Series(gene_pseudogene),\n"
     ]
    }
   ],
   "source": [
    "C_psittaci_df1 = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": pd.Series(locus_tag),\n",
    "        \"source\": pd.Series(source),\n",
    "        \"n_sequence\": pd.Series(n_sequence),\n",
    "        \"aa_sequence\": pd.Series(aa_sequence),\n",
    "        \"type_of_DNA_source\": pd.Series(DNA_source),\n",
    "        \"type_of_the_gene\": pd.Series(gene_pseudogene),\n",
    "        \"start_codone\": pd.Series(start_codone),\n",
    "        \"product\": pd.Series(product),\n",
    "        \"cog\": pd.Series(cog),\n",
    "        \"p_c_unity\": pd.Series(p_c_unity),\n",
    "        \"additional_info\": pd.Series(additional_info),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pn69F4e1d3rQ"
   },
   "source": [
    "For recoding COGs from ids to categories I have downloaded tsvs with all categories and appropriate COGs and have created python dictionary.\n",
    "Firstly I have uploaded tsvs to folder on google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0yBHPpptpWCx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 633.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# Creating cog dictionary\n",
    "cog_dict = {}\n",
    "current_path = \"../data/bigcog/\"\n",
    "cog_cats = os.listdir(current_path)\n",
    "for cog_cat in tqdm(cog_cats):\n",
    "    table = pd.read_csv(os.path.join(current_path, cog_cat), sep=\"\\t\")\n",
    "    if len(table.Cat):\n",
    "        cat = table.Cat.tolist()\n",
    "        cat_ful = list(map(lambda x: x.split(\" \"),cat))\n",
    "        cat_ful_single = list(chain.from_iterable(cat_ful))\n",
    "        key = max(cat_ful_single, key = cat_ful_single.count)\n",
    "        value = table.COG.tolist()\n",
    "        cog_dict[key] = value\n",
    "cog_dict[\"S\"].append(\"absent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2LzibiOtE-q"
   },
   "source": [
    "On the next stage I have created 25 new columns for dataset, each contained data if protein has this COG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "G586jo7svBP8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 25.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# Adding 25 columns to dataset\n",
    "for key in tqdm(cog_dict.keys()):   # Passing over COG categories\n",
    "    cog_list = []             # For each category create list\n",
    "    for cog_id in cog:        # Passing out every item\n",
    "        if cog_id not in cog_dict[key]:     # For every gene, if gene's id not in dict\n",
    "            cog_list.append(0)              # Mark it\n",
    "        else:                               \n",
    "            cog_list.append(1)              # Else mark another\n",
    "    C_psittaci_df1[key] = pd.Series(cog_list)   # Creating 25 new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3101107896.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [15], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    C_psittaci_df1.to_csv(\"../data/First_table.csv\")s;\u001b[0m\n\u001b[0m                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "C_psittaci_df1.to_csv(\"../data/First_table.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████████████                                                                      | 9/27 [00:00<00:00, 42.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998\n",
      "1094\n",
      "1018\n",
      "998\n",
      "985\n",
      "992\n",
      "994\n",
      "998\n",
      "999\n",
      "991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████████████████████▏                              | 19/27 [00:00<00:00, 43.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n",
      "1005\n",
      "1100\n",
      "992\n",
      "1011\n",
      "1071\n",
      "990\n",
      "991\n",
      "994\n",
      "991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 42.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1062\n",
      "999\n",
      "996\n",
      "1003\n",
      "994\n",
      "997\n",
      "1078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for source in tqdm(set(C_psittaci_df1[\"p_c_unity\"])):\n",
    "    subset = C_psittaci_df1[C_psittaci_df1[\"p_c_unity\"] == source]\n",
    "    with open (\"../data/orto_rows/C_psittaci\" + str(source) + \".fasta\", \"w\") as protein_fasta:\n",
    "        for index, row in subset.iterrows():\n",
    "            if row['type_of_the_gene'] != \"pseudogene\":\n",
    "                protein_fasta.write(\">\")\n",
    "                protein_fasta.write(row[\"id\"])\n",
    "                protein_fasta.write(\"_\")\n",
    "                protein_fasta.write(row[\"source\"])\n",
    "                protein_fasta.write(\"\\n\")\n",
    "                protein_fasta.write(row[\"aa_sequence\"])\n",
    "                protein_fasta.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "-WDRF29W3SyR",
    "c8yV-DwPre6C",
    "kyeKwO01rj1G",
    "Zyu27Lga0wWR",
    "dc_xdF-VxoMY",
    "2vlUfrmdJmyr",
    "qlF4YG3srZrF",
    "uuQtazSJwK_s",
    "N3J1A7ThS3Xz",
    "Kk6luKhoS3X0",
    "XrODV9lQS3X0"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
